{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2734dd",
   "metadata": {},
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d44bccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "stemmer = ISRIStemmer()\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from gensim.models import Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86548b10",
   "metadata": {},
   "source": [
    "# **Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15b17b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nتحصل كتاب \"المصحف وقراءاته\" الذي ألفه باحثون...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nاستنكرت إدارة المسرح الوطني التونسي الحملة ا...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nاحتضن جناح تونس في القرية الدولية للأفلام بم...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\nشهدت برلين أمس الجمعة افتتاح مسجد فريد من نو...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text     type\n",
       "0           0  \\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...  culture\n",
       "1           1  \\nتحصل كتاب \"المصحف وقراءاته\" الذي ألفه باحثون...  culture\n",
       "2           2  \\nاستنكرت إدارة المسرح الوطني التونسي الحملة ا...  culture\n",
       "3           3  \\nاحتضن جناح تونس في القرية الدولية للأفلام بم...  culture\n",
       "4           4  \\nشهدت برلين أمس الجمعة افتتاح مسجد فريد من نو...  culture"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\arabic_categorization_data.csv\\arabic_categorization_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2f2b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10366 entries, 0 to 10365\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  10366 non-null  int64 \n",
      " 1   text        10366 non-null  object\n",
      " 2   type        10366 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 243.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05faecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nتحصل كتاب \"المصحف وقراءاته\" الذي ألفه باحثون...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nاستنكرت إدارة المسرح الوطني التونسي الحملة ا...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nاحتضن جناح تونس في القرية الدولية للأفلام بم...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nشهدت برلين أمس الجمعة افتتاح مسجد فريد من نو...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     type\n",
       "0  \\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...  culture\n",
       "1  \\nتحصل كتاب \"المصحف وقراءاته\" الذي ألفه باحثون...  culture\n",
       "2  \\nاستنكرت إدارة المسرح الوطني التونسي الحملة ا...  culture\n",
       "3  \\nاحتضن جناح تونس في القرية الدولية للأفلام بم...  culture\n",
       "4  \\nشهدت برلين أمس الجمعة افتتاح مسجد فريد من نو...  culture"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['Unnamed: 0'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69793e",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2365d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove diacritics (tashkeel)\n",
    "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', '', text)\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e20eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Normalize Arabic characters\n",
    "    text = text.replace('أ', 'ا').replace('إ', 'ا').replace('آ', 'ا')\n",
    "    text = text.replace('ى', 'ي').replace('ة', 'ه')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3add083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    # Split text into tokens based on whitespace\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "934ceea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_stop_words = set(stopwords.words('arabic'))\n",
    "def remove_stopwords(tokens):\n",
    "    # Remove stopwords from the token list\n",
    "    filtered_tokens = [token for token in tokens if token not in arabic_stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4768ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    # Apply ISRIStemmer to each token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5d69baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(text):\n",
    "    # Split text into sentences using Arabic punctuation (۔, !, ؟)\n",
    "    sentence_pattern = r'[۔!؟]+'\n",
    "    sentences = [s.strip() for s in re.split(sentence_pattern, text) if s.strip()]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffdafb",
   "metadata": {},
   "source": [
    "# **Apply all the Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dd8b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(text):\n",
    "    # Apply each preprocessing step sequentially\n",
    "    cleaned_text = clean_text(text)\n",
    "    normalized_text = normalize_text(cleaned_text)\n",
    "    tokens = tokenize_text(normalized_text)\n",
    "    filtered_tokens = remove_stopwords(tokens)\n",
    "    stemmed_tokens = stem_tokens(filtered_tokens)\n",
    "    processed_text = ' '.join(stemmed_tokens)\n",
    "    # Segment sentences from the cleaned text (before tokenization)\n",
    "    sentences = segment_sentences(cleaned_text)\n",
    "    return processed_text, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aba501aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'], data['sentences'] = zip(*data['text'].apply(preprocess_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cfc1a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...</td>\n",
       "      <td>culture</td>\n",
       "      <td>شرف رئس جمهور بجي قيد سبس اليوم قصر قرطاج علي ...</td>\n",
       "      <td>[أشرف رئيس الجمهورية الباجي قايد السبسي اليوم ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nتحصل كتاب \"المصحف وقراءاته\" الذي ألفه باحثون...</td>\n",
       "      <td>culture</td>\n",
       "      <td>حصل كتب صحف وقراءاته الف بحث ونس تخصص علي جئز ...</td>\n",
       "      <td>[تحصل كتاب المصحف وقراءاته الذي ألفه باحثون تو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nاستنكرت إدارة المسرح الوطني التونسي الحملة ا...</td>\n",
       "      <td>culture</td>\n",
       "      <td>نكر دره سرح وطن ونس حمل شنه رلم كوت ضذ سرح وطن...</td>\n",
       "      <td>[استنكرت إدارة المسرح الوطني التونسي الحملة ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nاحتضن جناح تونس في القرية الدولية للأفلام بم...</td>\n",
       "      <td>culture</td>\n",
       "      <td>حضن جنح ونس قره دول فلم بمد رنس تضف دور سبع هر...</td>\n",
       "      <td>[احتضن جناح تونس في القرية الدولية للأفلام بمد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nشهدت برلين أمس الجمعة افتتاح مسجد فريد من نو...</td>\n",
       "      <td>culture</td>\n",
       "      <td>شهد برل امس جمع فتح سجد فرد نوع علي اقل علي ست...</td>\n",
       "      <td>[شهدت برلين أمس الجمعة افتتاح مسجد فريد من نوع...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     type  \\\n",
       "0  \\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...  culture   \n",
       "1  \\nتحصل كتاب \"المصحف وقراءاته\" الذي ألفه باحثون...  culture   \n",
       "2  \\nاستنكرت إدارة المسرح الوطني التونسي الحملة ا...  culture   \n",
       "3  \\nاحتضن جناح تونس في القرية الدولية للأفلام بم...  culture   \n",
       "4  \\nشهدت برلين أمس الجمعة افتتاح مسجد فريد من نو...  culture   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  شرف رئس جمهور بجي قيد سبس اليوم قصر قرطاج علي ...   \n",
       "1  حصل كتب صحف وقراءاته الف بحث ونس تخصص علي جئز ...   \n",
       "2  نكر دره سرح وطن ونس حمل شنه رلم كوت ضذ سرح وطن...   \n",
       "3  حضن جنح ونس قره دول فلم بمد رنس تضف دور سبع هر...   \n",
       "4  شهد برل امس جمع فتح سجد فرد نوع علي اقل علي ست...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [أشرف رئيس الجمهورية الباجي قايد السبسي اليوم ...  \n",
       "1  [تحصل كتاب المصحف وقراءاته الذي ألفه باحثون تو...  \n",
       "2  [استنكرت إدارة المسرح الوطني التونسي الحملة ال...  \n",
       "3  [احتضن جناح تونس في القرية الدولية للأفلام بمد...  \n",
       "4  [شهدت برلين أمس الجمعة افتتاح مسجد فريد من نوع...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41e69e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culture</td>\n",
       "      <td>شرف رئس جمهور بجي قيد سبس اليوم قصر قرطاج علي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>حصل كتب صحف وقراءاته الف بحث ونس تخصص علي جئز ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>culture</td>\n",
       "      <td>نكر دره سرح وطن ونس حمل شنه رلم كوت ضذ سرح وطن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>culture</td>\n",
       "      <td>حضن جنح ونس قره دول فلم بمد رنس تضف دور سبع هر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>culture</td>\n",
       "      <td>شهد برل امس جمع فتح سجد فرد نوع علي اقل علي ست...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                     processed_text\n",
       "0  culture  شرف رئس جمهور بجي قيد سبس اليوم قصر قرطاج علي ...\n",
       "1  culture  حصل كتب صحف وقراءاته الف بحث ونس تخصص علي جئز ...\n",
       "2  culture  نكر دره سرح وطن ونس حمل شنه رلم كوت ضذ سرح وطن...\n",
       "3  culture  حضن جنح ونس قره دول فلم بمد رنس تضف دور سبع هر...\n",
       "4  culture  شهد برل امس جمع فتح سجد فرد نوع علي اقل علي ست..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['text','sentences'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc1bf3",
   "metadata": {},
   "source": [
    "# **embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7b0d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tokenized sentences for Word2Vec\n",
    "tokenized_texts = [text.split() for text in data['processed_text']]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_texts,\n",
    "    vector_size=100,  # Same as embedding_dim\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=1  # Use Skip-gram (sg=1) or CBOW (sg=0)\n",
    ")\n",
    "\n",
    "# Save the Word2Vec model (optional)\n",
    "word2vec_model.save(\"word2vec_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857848c",
   "metadata": {},
   "source": [
    "# **Convert To Sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19427c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000  # Maximum number of words to consider in vocabulary\n",
    "max_len = 100      # Maximum sequence length\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['processed_text'])\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(data['processed_text'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58411bf8",
   "metadata": {},
   "source": [
    "# **Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4eefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35637918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a108462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebfe1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2259c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56746ada",
   "metadata": {},
   "source": [
    "# **Initialize The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc453c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\envs\\hegiproject\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100  # Size of the embedding vectors\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e1b54",
   "metadata": {},
   "source": [
    "# **compile The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5e94fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fc9b6",
   "metadata": {},
   "source": [
    "# **Train The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "886a5b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 89ms/step - accuracy: 0.4858 - loss: 1.6695 - val_accuracy: 0.6289 - val_loss: 1.0296\n",
      "Epoch 2/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.6929 - loss: 0.8762 - val_accuracy: 0.6926 - val_loss: 1.0113\n",
      "Epoch 3/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7734 - loss: 0.6324 - val_accuracy: 0.6990 - val_loss: 0.8713\n",
      "Epoch 4/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.8315 - loss: 0.4950 - val_accuracy: 0.7048 - val_loss: 0.9342\n",
      "Epoch 5/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - accuracy: 0.8587 - loss: 0.4004 - val_accuracy: 0.7177 - val_loss: 0.8987\n",
      "Epoch 6/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 107ms/step - accuracy: 0.8940 - loss: 0.3089 - val_accuracy: 0.7035 - val_loss: 0.9283\n",
      "Epoch 7/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 109ms/step - accuracy: 0.9149 - loss: 0.2533 - val_accuracy: 0.7344 - val_loss: 1.0270\n",
      "Epoch 8/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 123ms/step - accuracy: 0.9369 - loss: 0.1838 - val_accuracy: 0.6932 - val_loss: 0.9833\n",
      "Epoch 9/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 119ms/step - accuracy: 0.9503 - loss: 0.1700 - val_accuracy: 0.7357 - val_loss: 1.1597\n",
      "Epoch 10/10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 118ms/step - accuracy: 0.9540 - loss: 0.1409 - val_accuracy: 0.7100 - val_loss: 1.1642\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7cd5555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m585\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,378,269</span> (12.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,378,269\u001b[0m (12.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,126,089</span> (4.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,126,089\u001b[0m (4.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,252,180</span> (8.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,252,180\u001b[0m (8.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549611b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hegiproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
